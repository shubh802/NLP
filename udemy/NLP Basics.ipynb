{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "african-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "czech-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demanding-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying model to our doc\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ahead-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "norman-trance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x177cb1bdd48>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x177cb1c2048>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x177cb1c25e8>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abstract-drinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-combining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlikely-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't looking for the starups. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acoustic-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "n't ADV neg\n",
      "looking VERB ROOT\n",
      "for ADP prep\n",
      "the DET det\n",
      "starups NOUN pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "authorized-stereo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "consolidated-ceremony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntentic dependencies\n",
    "doc2[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "forbidden-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"This is the first sentence. This is the second sentence. This is another sentence. This is the last sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hollow-difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the second sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "irish-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "robust-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "mystring = 'We\\'re moving to L.A.!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bearing-train",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We're moving to L.A.!\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "thirty-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "renewable-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "moving\n",
      "to\n",
      "L.A.\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "destroyed-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"We're here to help! Send email, support@oursite.com or visit our website at http://oursite.com! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "chief-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "email\n",
      ",\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "our\n",
      "website\n",
      "at\n",
      "http://oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for t in doc2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "closed-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"A 5km can ride in NYC cost $10.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "spread-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "can\n",
      "ride\n",
      "in\n",
      "NYC\n",
      "cost\n",
      "$\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "multiple-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4= nlp(u\"Let's visit U.S. next year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stunning-authentication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "U.S.\n",
      "next\n",
      "year\n"
     ]
    }
   ],
   "source": [
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "boring-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x177c97d7b48>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "after-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc8=nlp(u\"Apple to build a Hong Kong facility for $6 Million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "blank-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | facility | for | $ | 6 | Million | "
     ]
    }
   ],
   "source": [
    "for token in doc8:\n",
    "    print(token.text,end=' | ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "numeric-thousand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "Hong Kong\n",
      "GPE\n",
      "Countries, cities, states\n",
      "\n",
      "\n",
      "$6 Million\n",
      "MONEY\n",
      "Monetary values, including unit\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entity in doc8.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)\n",
    "    print(str(spacy.explain(entity.label_)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "opponent-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability towards manufacturers!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "working-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dimensional-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "convenient-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Apple is going to build U.K. factory for $6 million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "damaged-triumph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"820\" height=\"242.0\" style=\"max-width: none; height: 242.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"120\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"120\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"190\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"190\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"260\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"260\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"330\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"330\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"540\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"540\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"152.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">million</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,107.0 C70,37.0 185.0,37.0 185.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,109.0 L62,97.0 78,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M140,107.0 C140,72.0 180.0,72.0 180.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M140,109.0 L132,97.0 148,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M280,107.0 C280,72.0 320.0,72.0 320.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M280,109.0 L272,97.0 288,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M210,107.0 C210,37.0 325.0,37.0 325.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M325.0,109.0 L333.0,97.0 317.0,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M420,107.0 C420,72.0 460.0,72.0 460.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,109.0 L412,97.0 428,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M350,107.0 C350,37.0 465.0,37.0 465.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M465.0,109.0 L473.0,97.0 457.0,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M350,107.0 C350,2.0 540.0,2.0 540.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M540.0,109.0 L548.0,97.0 532.0,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M630,107.0 C630,37.0 745.0,37.0 745.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M630,109.0 L622,97.0 638,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M700,107.0 C700,72.0 740.0,72.0 740.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,109.0 L692,97.0 708,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M560,107.0 C560,2.0 750.0,2.0 750.0,107.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,109.0 L758.0,97.0 742.0,97.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='dep',jupyter=True,options={'distance':70})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "tamil-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Over the last quater Apple sold nearly 20 thousands iPods for the profit of $2 million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "effective-compromise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Over the last quater \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    nearly 20 thousands\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for the profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $2 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Serving on port 5000...\u001b[0m\n",
      "    Using the 'dep' visualizer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Feb/2021 08:07:33] \"GET / HTTP/1.1\" 200 3058\n",
      "127.0.0.1 - - [21/Feb/2021 08:07:33] \"GET /favicon.ico HTTP/1.1\" 200 3058\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"This is the sentence\")\n",
    "displacy.serve(doc,style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-brand",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "focal-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "speaking-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preceding-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "satisfactory-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','ran','runs','easily','fairly','fairness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "honey-netscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run ---> run\n",
      "runner ---> runner\n",
      "ran ---> ran\n",
      "runs ---> run\n",
      "easily ---> easili\n",
      "fairly ---> fairli\n",
      "fairness ---> fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\" ---> \"+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "secure-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "indie-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mighty-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run ---> run\n",
      "runner ---> runner\n",
      "ran ---> ran\n",
      "runs ---> run\n",
      "easily ---> easili\n",
      "fairly ---> fair\n",
      "fairness ---> fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\" ---> \"+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "coordinate-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['generous','generation','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "characteristic-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous ---> generous\n",
      "generation ---> generat\n",
      "generously ---> generous\n",
      "generate ---> generat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word +\" ---> \"+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-retention",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "substantial-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "constant-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "impaired-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"I am a runner in a race because I love to run since I ran last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "western-disability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "am \t VERB \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t ADP \t 16950148841647037698 \t because\n",
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t ADP \t 10066841407251338481 \t since\n",
      "I \t PRON \t 561228191312463089 \t -PRON-\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "last \t ADJ \t 10321518907502812892 \t last\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-atlantic",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "occasional-indian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i', 'with', 'two', 'at', 'did', 'into', 'twelve', 'made', 'whether', 'since', 'moreover', 'hence', 'there', 'indeed', 'has', 'a', 'between', 'other', 'sometime', 'except', 'yourselves', 'otherwise', 'alone', 'also', 'am', 'next', 'same', 'whereafter', 'against', 'serious', 'who', 'and', 'mostly', 'perhaps', 'meanwhile', 'besides', 'others', 'whence', 'it', 'both', 'everyone', 'so', 'through', 'on', 'among', 'eleven', 'he', 'behind', 'how', 'within', 'latter', 'show', 'the', 'him', 'its', 'something', 'thru', 'either', 'because', 'some', 'top', 'several', 'until', 'would', 'becomes', 'most', 'his', 'done', 'name', 'regarding', 'in', 'which', 'further', 'her', 'become', 'less', 'such', 'anyway', 'nothing', 'six', 'anyone', 'about', 'hereupon', 'see', 'else', 'however', 'many', 'another', 'must', 'none', 'go', 'from', 'part', 'eight', 'those', 'was', 'fifty', 'various', 'beforehand', 'anyhow', 'do', 'least', 'via', 'enough', 'unless', 'down', 'throughout', 'what', 'me', 'whither', 'might', 'if', 'well', 'already', 'almost', 'be', 'became', 'before', 'but', 'for', 'she', 'whom', 'had', 'always', 'even', 'hereafter', 'herself', 'more', 'often', 'an', 'yours', 'over', 'thus', 'make', 'used', 'much', 'they', 'whereupon', 'mine', 'former', 'anything', 'bottom', 'each', 'thereafter', 'when', 'back', 'are', 'nevertheless', 'really', 'across', 'toward', 'get', 'please', 'around', 'somewhere', 'under', 'never', 'first', 'seemed', 'up', 'could', 'here', 'seems', 'whole', 'himself', 'nine', 'thence', 'no', 'to', 'move', 'amongst', 'somehow', 'us', 'can', 'side', 'all', 'by', 'quite', 'should', 'itself', 'fifteen', 'may', 'say', 'formerly', 'together', 'been', 'everywhere', 'them', 'themselves', 'put', 'doing', 'front', 'my', 'whereas', 'than', 'five', 'ever', 'four', 'last', 'is', 'nor', 'seeming', 'full', 'out', 'myself', 'that', 'although', 'onto', 'keep', 'own', 'per', 'whenever', 'above', 'sixty', 'this', 'herein', 'twenty', 'yourself', 'towards', 'hers', 'wherein', 'whatever', 'yet', 'every', 'hereby', 'whoever', 'off', 'ourselves', 'not', 'after', 'call', 'thereby', 'ca', 'nobody', 'neither', 'upon', 'thereupon', 'wherever', 'few', 'again', 'you', 'too', 'we', 'our', 'were', 'afterwards', 'of', 'their', 'any', 'below', 'nowhere', 'three', 'have', 'while', 'without', 'once', 'therefore', 'beside', 'forty', 'beyond', 'now', 'empty', 'everything', 'give', 'whose', 'does', 'using', 'hundred', 'whereby', 'then', 'therein', 'noone', 'cannot', 'or', 'namely', 'third', 'along', 'ours', 'just', 'anywhere', 'becoming', 'amount', 'during', 'due', 'why', 'though', 'seem', 'still', 'elsewhere', 'these', 're', 'as', 'take', 'sometimes', 'very', 'ten', 'only', 'your', 'latterly', 'someone', 'will', 'where', 'one', 'being', 'rather'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "liable-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "collect-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "relevant-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add stop words by default\n",
    "nlp.Defaults.stop_words.add('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "political-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "minor-coupon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "spanish-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "golden-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['beyaond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aggressive-preservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['beyaond'].is_stop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-providence",
   "metadata": {},
   "source": [
    "## Vocabulary Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "respiratory-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "superb-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "limited-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SolarPower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "#Solar-power\n",
    "pattern2 = [{'LOWER':'solar'},{\"IS_PUNCT\":True},{\"LOWERL\":'power'}]\n",
    "#Solar power\n",
    "pattern3 = [{'LOWER':'solar'},{\"LOWER\":'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "confirmed-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower',None,pattern1,pattern2,pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "hairy-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Solar power industry continues to grow as solarpower increases. Solar-power is amazing thing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "chinese-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 2), (8656102463236116519, 7, 8), (10088115319505432589, 10, 12)]\n"
     ]
    }
   ],
   "source": [
    "print(matcher(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "collectible-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase matching\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "previous-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "rolled-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Shubham\\\\Studies\\\\Data Science\\\\NLP\\\\udemy\\\\UPDATED_NLP_COURSE\\\\TextFiles\\\\reaganomics.txt') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "approved-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_list = ['voodo economics','supply-side economics','trickle-side economics','trickle-down economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "decreased-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "swiss-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrase_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acute-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('EconMatcher',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fantastic-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "incomplete-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3680293220734633682, 41, 45),\n",
       " (3680293220734633682, 49, 53),\n",
       " (3680293220734633682, 673, 677),\n",
       " (3680293220734633682, 2985, 2989)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "congressional-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 policies are commonly associated with supply-side economics, referred to as trickle\n",
      "3680293220734633682 EconMatcher 49 53 economics, referred to as trickle-down economics or voodoo economics by political\n",
      "3680293220734633682 EconMatcher 673 677 attracted a following from the supply-side economics movement, which formed in\n",
      "3680293220734633682 EconMatcher 2985 2989 became widely known as \"trickle-down economics\", due to the\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc3[start-5:end+5]\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-universe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
